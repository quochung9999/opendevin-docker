services:
  opendevin-docker:
    build: ./
    container_name: opendevin-docker
    privileged: true
    runtime: nvidia
    tty: true
    ulimits:
      memlock: -1
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility,video
    ports:
      - "80:80"
      - "3000:3000"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock"
      - "./nginx.conf:/etc/nginx/nginx.conf:ro"
    networks:
      - opendevin-docker

  webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: webui
    depends_on:
      - ollama
    ports:
      - "8080:8080"
    environment:
      - "OLLAMA_BASE_URL=http://ollama:11434"
      - 'WEBUI_SECRET_KEY='
    extra_hosts:
      - host.docker.internal:host-gateway
    networks:
      - opendevin-docker
    #volumes:
      #- /mnt/ssd/ai/open-webui:/app/backend/data

  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    privileged: true
    runtime: nvidia
    tty: true
    ulimits:
      memlock: -1
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility,video
    ports:
      - "11434:11434"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    networks:
      - opendevin-docker
    #volumes:
      #- /mnt/ssd/ai/ollama:/root/.ollama

networks:
  opendevin-docker:
    external: true
    name: opendevin-docker
